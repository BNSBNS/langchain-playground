{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperate = randomness, 0 == same result always\n",
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Bak Kut Teh\n",
      "2. Chilli Crab\n",
      "3. Hainanese Chicken Rice\n",
      "4. Nasi Lemak\n",
      "5. Laksa\n"
     ]
    }
   ],
   "source": [
    "text = \"what are 5 good food to eat in Singapore?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template object\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['food'],\n",
    "    template='what are 5 places to eat nice {food}?',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are 5 places to eat nice dessert?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food='dessert'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cheesecake Factory \n",
      "2. Max Brenner \n",
      "3. Magnolia Bakery \n",
      "4. Cold Stone Creamery \n",
      "5. Baskin-Robbins\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(llm(prompt.format(food='dessert')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain, combine LLM and prompts in multi step workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['food'],\n",
    "    template=\"what are 5 vacation destinations for someone who likes to eat {food}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Costa Rica - papaya, melon, pineapple, mango and guava \n",
      "2. Hawaii - lychee, passion fruit, starfruit, pineapple and banana \n",
      "3. Thailand - durian, dragonfruit, jackfruit, mangosteen and rambutan \n",
      "4. India - lychee, mango, banana, guava and pomegranate \n",
      "5. South Africa - lychee, pineapple, apple, banana and peach\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(chain.run(\"fruit\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents call chains based on user Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs serpapi api key SERPAPI_API_KEY , llm-math is free\n",
    "tools = load_tools(['serpapi', 'llm-math'],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an agent\n",
    "# verbose = true will show its process, thought process\n",
    "agent = initialize_agent(tools, llm, agent='zero-shot-react-description', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to research the pros and cons of allowing chewing gums in Singapore.\n",
      "Action: Search\n",
      "Action Input: Pros and cons of allowing chewing gums in Singapore\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIt is not illegal to chew gum in Singapore, but it is against the law to import it and sell it, apart from the aforementioned exceptions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to research the potential benefits of allowing chewing gums in Singapore.\n",
      "Action: Search\n",
      "Action Input: Benefits of allowing chewing gums in Singapore\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIt has always been legal to bring small amounts into the country for one's own use. Since 2004 - as a result of the US-Singapore Free Trade ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the potential benefits and drawbacks of allowing chewing gums in Singapore.\n",
      "Final Answer: Allowing chewing gums in Singapore could potentially bring economic benefits, but it could also lead to increased littering and other negative consequences. Therefore, it is important to consider the potential pros and cons before making a decision.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Allowing chewing gums in Singapore could potentially bring economic benefits, but it could also lead to increased littering and other negative consequences. Therefore, it is important to consider the potential pros and cons before making a decision.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"If Singapore were to allow chewing gums, will it be a good move by the government?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add state to chains and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there whats up !?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! I'm doing great. How about you?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there whats up !?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
