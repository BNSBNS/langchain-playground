{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import TypedDict, Annotated\n",
    "# from langgraph.graph.message import add_messages\n",
    "# from langchain_core.messages import AnyMessage, HumanMessage, AIMessage\n",
    "# from langgraph.prebuilt import ToolNode\n",
    "# from langgraph.graph import START, StateGraph\n",
    "# from langgraph.prebuilt import tools_condition\n",
    "# from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "# # Generate the chat interface, including the tools\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
    "# )\n",
    "\n",
    "# chat = ChatHuggingFace(llm=llm, verbose=True)\n",
    "# tools = [guest_info_tool]\n",
    "# chat_with_tools = chat.bind_tools(tools)\n",
    "\n",
    "# # Generate the AgentState and Agent graph\n",
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# def assistant(state: AgentState):\n",
    "#     return {\n",
    "#         \"messages\": [chat_with_tools.invoke(state[\"messages\"])],\n",
    "#     }\n",
    "\n",
    "# ## The graph\n",
    "# builder = StateGraph(AgentState)\n",
    "\n",
    "# # Define nodes: these do the work\n",
    "# builder.add_node(\"assistant\", assistant)\n",
    "# builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# # Define edges: these determine how the control flow moves\n",
    "# builder.add_edge(START, \"assistant\")\n",
    "# builder.add_conditional_edges(\n",
    "#     \"assistant\",\n",
    "#     # If the latest message requires a tool, route to tools\n",
    "#     # Otherwise, provide a direct response\n",
    "#     tools_condition,\n",
    "# )\n",
    "# builder.add_edge(\"tools\", \"assistant\")\n",
    "# alfred = builder.compile()\n",
    "\n",
    "# messages = [HumanMessage(content=\"Tell me about our guest named 'Lady Ada Lovelace'.\")]\n",
    "# response = alfred.invoke({\"messages\": messages})\n",
    "\n",
    "# print(\"ðŸŽ© Alfred's Response:\")\n",
    "# print(messages['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Load the dataset\n",
    "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
    "\n",
    "# Convert dataset entries into Document objects\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"\\n\".join([\n",
    "            f\"Name: {guest['name']}\",\n",
    "            f\"Relation: {guest['relation']}\",\n",
    "            f\"Description: {guest['description']}\",\n",
    "            f\"Email: {guest['email']}\"\n",
    "        ]),\n",
    "        metadata={\"name\": guest[\"name\"]}\n",
    "    )\n",
    "    for guest in guest_dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.tools import Tool\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "\n",
    "def extract_text(query: str) -> str:\n",
    "    \"\"\"Retrieves detailed information about gala guests based on their name or relation.\"\"\"\n",
    "    results = bm25_retriever.invoke(query)\n",
    "    if results:\n",
    "        return \"\\n\\n\".join([doc.text for doc in results[:3]])\n",
    "    else:\n",
    "        return \"No matching guest information found.\"\n",
    "\n",
    "guest_info_tool = Tool(\n",
    "    name=\"guest_info_retriever\",\n",
    "    func=extract_text,\n",
    "    description=\"Retrieves detailed information about gala guests based on their name or relation.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "<think>\n",
      "Okay, let me try to figure out what went wrong here. The user asked about Lady Ada Lovelace, and I tried to use the guest_info_retriever function. But there was an error: AttributeError(\"'Document' object has no attribute 'text'\"). Hmm, that error usually means that somewhere in the code, there's an attempt to access the 'text' attribute of a 'Document' object, which doesn't exist.\n",
      "\n",
      "Wait, maybe the function I called isn't correctly implemented yet? The user provided the function definition, but maybe the actual backend for guest_info_retriever isn't set up properly. The error might be on their side, but as the assistant, I need to handle it gracefully.\n",
      "\n",
      "Alternatively, perhaps the function expects a different parameter format. Let me check the function signature again. The function requires \"__arg1\" which is a string. I used \"Lady Ada Lovelace\" as the argument, which is a string. So the parameter seems correct.\n",
      "\n",
      "Maybe the error is in how the function is being called or processed. Since the error mentions 'Document' object, maybe the system is trying to process the input as a Document object but can't find the text. Perhaps there's a middleware or a step before the function is called that's mishandling the input.\n",
      "\n",
      "Alternatively, maybe the function is supposed to return a Document object, and there's an attempt to access its 'text' attribute which isn't there. But that's part of the function's implementation, which I can't control. \n",
      "\n",
      "Since the user is getting this error, I should inform them that there was a technical issue with retrieving the information. I should apologize and suggest that they try again or check if the guest's name is correctly spelled. Maybe offer to help with another query in the meantime. \n",
      "\n",
      "I need to make sure my response is helpful and not technical jargon. Let me phrase it in a friendly way to maintain user trust.\n",
      "</think>\n",
      "\n",
      "I encountered an error while trying to retrieve information about Lady Ada Lovelace. It looks like there's a technical issue with accessing guest details at the moment. Would you like me to try again, or is there another way I can assist you in the meantime?\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Use LangChainâ€™s Ollama chat model\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize the Ollama chat model\n",
    "chat = ChatOllama(\n",
    "    # model=\"qwen2.5:14b\",\n",
    "    model=\"qwq\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Bind your tools\n",
    "tools = [guest_info_tool]\n",
    "chat_with_tools = chat.bind_tools(tools)\n",
    "\n",
    "# Define the AgentState\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# The assistant node\n",
    "def assistant(state: AgentState):\n",
    "    return {\n",
    "        \"messages\": [chat_with_tools.invoke(state[\"messages\"])],\n",
    "    }\n",
    "\n",
    "# Build the state graph\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "alfred = builder.compile()\n",
    "\n",
    "# Run it\n",
    "messages = [HumanMessage(content=\"Tell me about our guest named 'Lady Ada Lovelace'.\")]\n",
    "response = alfred.invoke({\"messages\": messages})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # qwen2.5 14b reply: ðŸŽ© Alfred's Response:\n",
    "# It seems there is an issue with the tool's response format or the way information is being retrieved. I'm receiving an error because the tool might be expecting a different type of input or there could be an internal problem.\n",
    "\n",
    "# However, without fixing the technical aspect right away, let me attempt to provide you with what we generally know about Lady Ada Lovelace:\n",
    "\n",
    "# Lady Ada Lovelace (born Augusta Ada King, Countess of Lovelace) is widely recognized as one of the world's first computer programmers. She worked closely with Charles Babbage on his Analytical Engine and wrote notes that included what is now considered to be the first algorithm intended to be processed by a machine. This makes her a pioneer in the field of computer science.\n",
    "\n",
    "# Would you like more specific information about Lady Ada Lovelace or help with another query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwq\n",
    "\n",
    "# ðŸŽ© Alfred's Response:\n",
    "# <think>\n",
    "# Okay, let me try to figure out what went wrong here. The user asked about Lady Ada Lovelace, and I tried to use the guest_info_retriever function. But there was an error: AttributeError(\"'Document' object has no attribute 'text'\"). Hmm, that error usually means that somewhere in the code, there's an attempt to access the 'text' attribute of a 'Document' object, which doesn't exist.\n",
    "\n",
    "# Wait, maybe the function I called isn't correctly implemented yet? The user provided the function definition, but maybe the actual backend for guest_info_retriever isn't set up properly. The error might be on their side, but as the assistant, I need to handle it gracefully.\n",
    "\n",
    "# Alternatively, perhaps the function expects a different parameter format. Let me check the function signature again. The function requires \"__arg1\" which is a string. I used \"Lady Ada Lovelace\" as the argument, which is a string. So the parameter seems correct.\n",
    "\n",
    "# Maybe the error is in how the function is being called or processed. Since the error mentions 'Document' object, maybe the system is trying to process the input as a Document object but can't find the text. Perhaps there's a middleware or a step before the function is called that's mishandling the input.\n",
    "\n",
    "# Alternatively, maybe the function is supposed to return a Document object, and there's an attempt to access its 'text' attribute which isn't there. But that's part of the function's implementation, which I can't control. \n",
    "\n",
    "# Since the user is getting this error, I should inform them that there was a technical issue with retrieving the information. I should apologize and suggest that they try again or check if the guest's name is correctly spelled. Maybe offer to help with another query in the meantime. \n",
    "\n",
    "# I need to make sure my response is helpful and not technical jargon. Let me phrase it in a friendly way to maintain user trust.\n",
    "# </think>\n",
    "\n",
    "# I encountered an error while trying to retrieve information about Lady Ada Lovelace. It looks like there's a technical issue with accessing guest details at the moment. Would you like me to try again, or is there another way I can assist you in the meantime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "from tools import DuckDuckGoSearchRun, weather_info_tool, hub_stats_tool\n",
    "from retriever import guest_info_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine to single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the web search tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Generate the chat interface, including the tools\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=llm, verbose=True)\n",
    "tools = [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool]\n",
    "chat_with_tools = chat.bind_tools(tools)\n",
    "\n",
    "# Generate the AgentState and Agent graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    return {\n",
    "        \"messages\": [chat_with_tools.invoke(state[\"messages\"])],\n",
    "    }\n",
    "\n",
    "## The graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message requires a tool, route to tools\n",
    "    # Otherwise, provide a direct response\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "alfred = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = alfred.invoke({\"messages\": \"Tell me about 'Lady Ada Lovelace'\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = alfred.invoke({\"messages\": \"Tell me about 'Lady Ada Lovelace'\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = alfred.invoke({\"messages\": \"One of our guests is from Qwen. What can you tell me about their most popular model?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = alfred.invoke({\"messages\":\"I need to speak with 'Dr. Nikola Tesla' about recent advancements in wireless energy. Can you help me prepare for this conversation?\"})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First interaction\n",
    "response = alfred.invoke({\"messages\": [HumanMessage(content=\"Tell me about 'Lady Ada Lovelace'. What's her background and how is she related to me?\")]})\n",
    "\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)\n",
    "print()\n",
    "\n",
    "# Second interaction (referencing the first)\n",
    "response = alfred.invoke({\"messages\": response[\"messages\"] + [HumanMessage(content=\"What projects is she currently working on?\")]})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
