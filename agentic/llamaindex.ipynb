{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# import os\n",
    "\n",
    "# # login(token=os.environ['HF_TOKEN'])\n",
    "\n",
    "\n",
    "# from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "\n",
    "# llm = HuggingFaceInferenceAPI(\n",
    "#     model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=100,\n",
    "#     token=os.environ['HF_TOKEN'],\n",
    "# )\n",
    "\n",
    "# llm.complete(\"Hello, how are you?\")\n",
    "# # # I am good, how can I help you today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.agent.workflow import AgentWorkflow, ReActAgent\n",
    "# from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "\n",
    "# # Define some tools\n",
    "# def add(a: int, b: int) -> int:\n",
    "#     \"\"\"Add two numbers.\"\"\"\n",
    "#     return a + b\n",
    "\n",
    "# def multiply(a: int, b: int) -> int:\n",
    "#     \"\"\"Multiply two numbers.\"\"\"\n",
    "#     return a * b\n",
    "\n",
    "# llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "\n",
    "# # we can pass functions directly without FunctionTool -- the fn/docstring are parsed for the name/description\n",
    "# multiply_agent = ReActAgent(\n",
    "#     name=\"multiply_agent\",\n",
    "#     description=\"Is able to multiply two integers\",\n",
    "#     system_prompt=\"A helpful assistant that can use a tool to multiply numbers.\",\n",
    "#     tools=[multiply],\n",
    "#     llm=llm,\n",
    "# )\n",
    "\n",
    "# addition_agent = ReActAgent(\n",
    "#     name=\"add_agent\",\n",
    "#     description=\"Is able to add two integers\",\n",
    "#     system_prompt=\"A helpful assistant that can use a tool to add numbers.\",\n",
    "#     tools=[add],\n",
    "#     llm=llm,\n",
    "# )\n",
    "\n",
    "# # Create the workflow\n",
    "# workflow = AgentWorkflow(\n",
    "#     agents=[multiply_agent, addition_agent],\n",
    "#     root_agent=\"multiply_agent\",\n",
    "# )\n",
    "\n",
    "# # Run the system\n",
    "# response = await workflow.run(user_msg=\"Can you add 5 and 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting ad don the counter\n",
    "\n",
    "# from llama_index.core.workflow import Context\n",
    "\n",
    "# # Define some tools\n",
    "# async def add(ctx: Context, a: int, b: int) -> int:\n",
    "#     \"\"\"Add two numbers.\"\"\"\n",
    "#     # update our count\n",
    "#     cur_state = await ctx.get(\"state\")\n",
    "#     cur_state[\"num_fn_calls\"] += 1\n",
    "#     await ctx.set(\"state\", cur_state)\n",
    "\n",
    "#     return a + b\n",
    "\n",
    "# async def multiply(ctx: Context, a: int, b: int) -> int:\n",
    "#     \"\"\"Multiply two numbers.\"\"\"\n",
    "#     # update our count\n",
    "#     cur_state = await ctx.get(\"state\")\n",
    "#     cur_state[\"num_fn_calls\"] += 1\n",
    "#     await ctx.set(\"state\", cur_state)\n",
    "\n",
    "#     return a * b\n",
    "\n",
    "# ...\n",
    "\n",
    "# workflow = AgentWorkflow(\n",
    "#     agents=[multiply_agent, addition_agent],\n",
    "#     root_agent=\"multiply_agent\"\n",
    "#     initial_state={\"num_fn_calls\": 0},\n",
    "#     state_prompt=\"Current state: {state}. User message: {msg}\",\n",
    "# )\n",
    "\n",
    "# # run the workflow with context\n",
    "# ctx = Context(workflow)\n",
    "# response = await workflow.run(user_msg=\"Can you add 5 and 3?\", ctx=ctx)\n",
    "\n",
    "# # pull out and inspect the state\n",
    "# state = await ctx.get(\"state\")\n",
    "# print(state[\"num_fn_calls\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
